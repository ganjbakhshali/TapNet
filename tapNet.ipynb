{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "class SignalGating(nn.Module):\n",
        "    def __init__(self, threshold=0.5, window_size=120, sampling_rate=416):\n",
        "        super(SignalGating, self).__init__()\n",
        "        self.threshold = threshold  # Threshold for peak detection\n",
        "        self.window_size = window_size  # Window size in milliseconds\n",
        "        self.sampling_rate = sampling_rate  # Sensor sampling rate\n",
        "        self.samples_per_window = 50  # Fixed number of samples per channel\n",
        "\n",
        "    def forward(self, imu_data):\n",
        "        \"\"\"\n",
        "        Input: imu_data - Tensor of shape (6, N), where 6 channels: [accel_x, accel_y, accel_z, gyro_x, gyro_y, gyro_z]\n",
        "        Output: Flattened Tensor of shape (300,)\n",
        "        \"\"\"\n",
        "        if isinstance(imu_data, np.ndarray):\n",
        "            imu_data = torch.tensor(imu_data, dtype=torch.float32)\n",
        "\n",
        "        # Use the Z-axis accelerometer signal for peak detection\n",
        "        accel_z = imu_data[2]  # Z-axis of accelerometer\n",
        "\n",
        "        # Detect peaks in the Z-axis signal\n",
        "        peaks, _ = find_peaks(accel_z.detach().cpu().numpy(), height=self.threshold)\n",
        "        windows = []\n",
        "\n",
        "        for peak in peaks:\n",
        "            start = max(peak - self.samples_per_window // 2, 0)\n",
        "            end = min(peak + self.samples_per_window // 2, accel_z.shape[0])\n",
        "\n",
        "            # Extract 50 samples from each of the 6 channels\n",
        "            window = imu_data[:, start:end]\n",
        "            if window.shape[1] == self.samples_per_window:\n",
        "                # Flatten the window to shape (300,)\n",
        "                flattened_window = window.flatten()\n",
        "                windows.append(flattened_window)\n",
        "\n",
        "        return windows\n",
        "\n",
        "# Test sample\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate a test signal with random peaks for 6 channels\n",
        "    np.random.seed(0)\n",
        "    test_signal = np.random.normal(0, 0.1, (6, 1000))\n",
        "    test_signal[2, 200] = 1.0  # Simulated tap peak on accel_z\n",
        "    test_signal[2, 600] = 1.2  # Simulated tap peak on accel_z\n",
        "\n",
        "    gating = SignalGating(threshold=0.5)\n",
        "    detected_windows = gating(torch.tensor(test_signal))\n",
        "\n",
        "    print(f\"Number of detected taps: {len(detected_windows)}\")\n",
        "    for i, window in enumerate(detected_windows):\n",
        "        print(f\"Window {i+1} shape: {window.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ5wea6fDgUb",
        "outputId": "76bb2b25-4a78-4287-9d4c-43158037ffe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of detected taps: 2\n",
            "Window 1 shape: torch.Size([300])\n",
            "Window 2 shape: torch.Size([300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchviz import make_dot\n",
        "\n",
        "class TapNet(nn.Module):\n",
        "    def __init__(self, device_info_dim=5):\n",
        "        super(TapNet, self).__init__()\n",
        "        self.device_info_dim = device_info_dim  # Device vector size\n",
        "\n",
        "        # Shared Convolutional Layers\n",
        "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3)  # Output: (298, 32)\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=2)      # Output: (148, 32)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3) # Output: (146, 64)\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2)      # Output: (72, 64)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(64, 64, kernel_size=3) # Output: (70, 64)\n",
        "        self.pool3 = nn.MaxPool1d(kernel_size=2)      # Output: (34, 64)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(64, 64, kernel_size=3, padding=1)  # Output: (34, 64)\n",
        "\n",
        "        self.flatten = nn.Flatten()  # Output: 2176\n",
        "        self.fc_shared = nn.Linear(2176, 64)  # Fully connected layer before branching\n",
        "\n",
        "        self.concat_dim = 64 + device_info_dim\n",
        "\n",
        "        # Branch 1: Tap Event Detection (Binary)\n",
        "        self.branch1_fc1 = nn.Linear(self.concat_dim, 8)\n",
        "        self.branch1_fc2 = nn.Linear(8, 4)\n",
        "        self.branch1_fc3 = nn.Linear(4, 2)\n",
        "\n",
        "        # Branch 2: Tap Direction (6 Classes)\n",
        "        self.branch2_fc1 = nn.Linear(self.concat_dim, 8)\n",
        "        self.branch2_fc2 = nn.Linear(8, 7)\n",
        "        self.branch2_fc3 = nn.Linear(7, 6)\n",
        "\n",
        "        # Branch 3: Finger Part (2 Classes)\n",
        "        self.branch3_fc1 = nn.Linear(self.concat_dim, 32)\n",
        "        self.branch3_fc2 = nn.Linear(32, 8)\n",
        "        self.branch3_fc3 = nn.Linear(8, 2)\n",
        "\n",
        "        # Branch 4: Location Classification (35 Classes)\n",
        "        self.branch4_fc1 = nn.Linear(self.concat_dim, 32)\n",
        "        self.branch4_fc2 = nn.Linear(32, 35)\n",
        "\n",
        "        # Branch 5: Location Regression (2 values for X and Y)\n",
        "        self.branch5_fc1 = nn.Linear(self.concat_dim, 8)\n",
        "        self.branch5_fc2 = nn.Linear(8, 4)\n",
        "        self.branch5_fc3 = nn.Linear(4, 2)\n",
        "\n",
        "    def forward(self, x, device_info):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc_shared(x))\n",
        "        combined = torch.cat((x, device_info.float()), dim=1)\n",
        "\n",
        "        # Branch 1: Tap Event Detection\n",
        "        b1 = F.relu(self.branch1_fc1(combined))\n",
        "        b1 = F.relu(self.branch1_fc2(b1))\n",
        "        b1 = self.branch1_fc3(b1)\n",
        "\n",
        "        # Branch 2: Tap Direction\n",
        "        b2 = F.relu(self.branch2_fc1(combined))\n",
        "        b2 = F.relu(self.branch2_fc2(b2))\n",
        "        b2 = self.branch2_fc3(b2)\n",
        "\n",
        "        # Branch 3: Finger Part\n",
        "        b3 = F.relu(self.branch3_fc1(combined))\n",
        "        b3 = F.relu(self.branch3_fc2(b3))\n",
        "        b3 = self.branch3_fc3(b3)\n",
        "\n",
        "        # Branch 4: Location Classification\n",
        "        b4 = F.relu(self.branch4_fc1(combined))\n",
        "        b4 = self.branch4_fc2(b4)\n",
        "\n",
        "        # Branch 5: Location Regression\n",
        "        b5 = F.relu(self.branch5_fc1(combined))\n",
        "        b5 = F.relu(self.branch5_fc2(b5))\n",
        "        b5 = self.branch5_fc3(b5)\n",
        "\n",
        "        return b1, b2, b3, b4, b5\n",
        "\n",
        "# Training and Testing Functions\n",
        "def train_model(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for signals, device_info, labels in dataloader:\n",
        "        signals, device_info = signals.to(device), device_info.to(device)\n",
        "        labels = [label.to(device) for label in labels]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(signals, device_info)\n",
        "        loss = sum(criterion(out, label) for out, label in zip(outputs, labels))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def test_model(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for signals, device_info, labels in dataloader:\n",
        "            signals, device_info = signals.to(device), device_info.to(device)\n",
        "            labels = [label.to(device) for label in labels]\n",
        "            outputs = model(signals, device_info)\n",
        "            loss = sum(criterion(out, label) for out, label in zip(outputs, labels))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Example Training Loop\n",
        "if __name__ == \"__main__\":\n",
        "    model = TapNet().to('cuda')\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        train_loss = train_model(model, train_loader, optimizer, criterion, 'cuda')\n",
        "        test_loss = test_model(model, test_loader, criterion, 'cuda')\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "cQhqFSpSE5E8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}